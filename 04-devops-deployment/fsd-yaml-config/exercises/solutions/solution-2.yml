# Solution 2: EKS Microservice Deployment
# Recommendation service with autoscaling and proper resource management

name: recommendation-service
platform: eks
description: ML-powered product recommendation service for e-commerce platform

team: ml-platform
tags:
  environment: production
  tier: api
  cost-center: ml

# EKS compute configuration with Kubernetes-style resources
compute:
  replicas: 3

  resources:
    requests:
      cpu: "500m"        # 500 millicores = 0.5 vCPU
      memory: "512Mi"    # 512 mebibytes
    limits:
      cpu: "1000m"       # 1000 millicores = 1 vCPU
      memory: "1Gi"      # 1 gibibyte

  # Horizontal Pod Autoscaler configuration
  autoscaling:
    enabled: true
    min_replicas: 2
    max_replicas: 15
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 70

# Node scheduling constraints
scheduling:
  node_selector:
    workload-type: api

  tolerations:
    - key: dedicated
      operator: Equal
      value: api
      effect: NoSchedule

# Health probes for Kubernetes
probes:
  readiness:
    http_get:
      path: /ready
      port: 8080
    initial_delay_seconds: 10
    period_seconds: 5
    timeout_seconds: 3
    success_threshold: 1
    failure_threshold: 3

  liveness:
    http_get:
      path: /health
      port: 8080
    initial_delay_seconds: 10
    period_seconds: 15
    timeout_seconds: 5
    success_threshold: 1
    failure_threshold: 3

# Pod disruption budget (bonus challenge)
pod_disruption_budget:
  min_available: 2

# Environment variables
environment:
  MODEL_ENDPOINT: ${ssm:/recommendation/model-endpoint}
  CACHE_TTL: "300"
  MAX_RECOMMENDATIONS: "10"
  LOG_FORMAT: json
