# Example 3: Kafka Dependencies
# An event-driven order processor using Kafka for messaging
# Demonstrates Kafka consumer and producer patterns

name: order-processor
platform: eks
description: Processes order events and publishes downstream events

team: orders-team
tags:
  environment: production
  tier: event-processor
  cost-center: orders

compute:
  replicas: 5
  resources:
    requests:
      cpu: "500m"
      memory: "512Mi"
    limits:
      cpu: "1000m"
      memory: "1Gi"

  autoscaling:
    enabled: true
    min_replicas: 3
    max_replicas: 20
    metrics:
      - type: External
        external:
          metric:
            name: kafka_consumer_lag
          target:
            type: AverageValue
            averageValue: "1000"

# Kafka and supporting dependencies
dependencies:
  # Consume order events from orders topic
  - type: kafka_topic
    name: order-events
    mode: consumer
    consumer_group: order-processor
    bootstrap_servers: ${ssm:/kafka/bootstrap-servers}

    # Consumer configuration
    auto_offset_reset: earliest
    enable_auto_commit: false  # Manual commits for at-least-once
    max_poll_records: 100
    session_timeout_ms: 30000
    heartbeat_interval_ms: 10000

  # Consume payment confirmation events
  - type: kafka_topic
    name: payment-events
    mode: consumer
    consumer_group: order-processor
    bootstrap_servers: ${ssm:/kafka/bootstrap-servers}
    auto_offset_reset: latest

  # Produce inventory reservation events
  - type: kafka_topic
    name: inventory-events
    mode: producer
    bootstrap_servers: ${ssm:/kafka/bootstrap-servers}

    # Producer configuration
    acks: all
    retries: 3
    retry_backoff_ms: 100
    compression_type: lz4

  # Produce shipping notification events
  - type: kafka_topic
    name: shipping-events
    mode: producer
    bootstrap_servers: ${ssm:/kafka/bootstrap-servers}
    acks: all

  # Produce analytics events (fire and forget)
  - type: kafka_topic
    name: analytics-events
    mode: producer
    bootstrap_servers: ${ssm:/kafka/bootstrap-servers}
    acks: "1"  # Leader ack only for analytics

  # Order state storage
  - type: aws_dynamodb_table
    name: orders
    mode: read_write
    indexes:
      - name: customer-index
        mode: read
      - name: status-index
        mode: read

  # Cache for idempotency and deduplication
  - type: aws_elasticache
    name: order-cache
    engine: redis
    mode: read_write

environment:
  KAFKA_BOOTSTRAP: ${ssm:/kafka/bootstrap-servers}
  KAFKA_CONSUMER_GROUP: order-processor
  ORDERS_TABLE: orders
  REDIS_URL: ${elasticache:order-cache:url}
  LOG_FORMAT: json
  OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
